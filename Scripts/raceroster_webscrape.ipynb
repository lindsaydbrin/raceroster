{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scrape for triathlon results from the Race Roster website\n",
    "\n",
    "Lindsay Brin\n",
    "start 2018 June 25\n",
    "\n",
    "Based on initial scrape of Hampton Ladies Triathlon 2018 results in `raceroster_webscrape_hampton.pynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding additional data:\n",
    "\n",
    "* If headers follow the same general approach as previous data:\n",
    "    * Add info to `race_info` dictionary.\n",
    "        * Confirm that URL allows for all data to be shown on that page (e.g., if limit is 500 rows shown, make sure there are not more than 500 participants).\n",
    "    * Add header cleanup to `header_replacement` dictionary as necessary.\n",
    "* If headers follow some new, creative format:\n",
    "    * All bets are off. Figure out if `get_rr_table()` works and then go from there.  Once it works, we should be back in the territory of the previous bullet point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from lxml import html\n",
    "from lxml import etree\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data as table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get (single) table from website, extract (multi-line) headers and body, and combine as a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers are only combined if the colspan value in the first row > 1.\n",
    "# This means that for 2018 races where the header value is repeated in both rows, only the first row value is used.  \n",
    "# Specifically, the second row value is set to \"\" because colspan == 1.\n",
    "def get_rr_table(url):\n",
    "    page = requests.get(url)\n",
    "    tree = html.fromstring(page.content)\n",
    "    \n",
    "    for table in tree.xpath('//table[@class=\"results-listing__table table table-hover table-striped\"]'):\n",
    "        # Get both header rows\n",
    "        header1 = [th.text_content().strip().lower() for th in table.xpath('//thead/tr[1]/th')]\n",
    "        header2 = [th.text_content().strip().lower() for th in table.xpath('//thead/tr[2]/th')]\n",
    "        # Get colspan (and rowspan?) attributes/values, then convert instances of None to 1; also, convert to integers\n",
    "        colspan1 = [th.get(\"colspan\") for th in table.xpath('//thead/tr[1]/th')]\n",
    "        colspan1_int = [1 if element == None else int(element) for element in colspan1]\n",
    "        # Make expanded header 1 (repeat elements as necessary)\n",
    "        header1_expanded = [item for item, count in zip(header1, colspan1_int) for i in range(count)]\n",
    "        # Make corrected header 2 (align elements to header 1)\n",
    "        # For each element in colspan1_int, add an empty string if the orignal value was None,\n",
    "        #   and select the appropriate number of elements from header2 if colspan1_int >1.\n",
    "        #   I could have done this as simply appending elements from header2, but I wanted to \n",
    "        #   write it so that it might still make sense with a different race roster header pattern.\n",
    "        header2_expanded = []  # Initialize empty list\n",
    "        strloc = 0  # Initialize counter variable\n",
    "        for i in colspan1_int:\n",
    "            if i == 1:\n",
    "                header2_expanded.append('')\n",
    "            elif i > 1:\n",
    "                header2_expanded.extend(['-' + element for element in header2[strloc:strloc+i]]) # extend concatenates elements from the list, rather than appending a list (as a sub-list)\n",
    "                strloc += i    \n",
    "        # Combine header rows\n",
    "        header = [h1 + h2 for h1, h2 in zip(header1_expanded, header2_expanded)]\n",
    "        # Get body of table; remove white spaces and \\n; only keep the rows that are the right number of elements\n",
    "        data = [[td.text_content() for td in tr.xpath('td')]  \n",
    "                for tr in table.xpath('//tr')]\n",
    "        for lst in np.arange(start = 0, stop = (len(data)), step = 1):\n",
    "            data[lst] = [element.strip() for element in data[lst]]\n",
    "        data = [row for row in data if len(row)==len(header)]\n",
    "        # Convert to pandas dataframe\n",
    "        data = pd.DataFrame(data, columns=header)\n",
    "        return(data)  # Return pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set variables for each race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_info = {'Hampton2017': {\n",
    "                 'url': 'https://results.raceroster.com/results/sj47pnd6egmunhjt', \n",
    "                 'dfname': 'hampton17sprint', \n",
    "             }, \n",
    "             'Hampton2018': {\n",
    "                 'url': 'https://results.raceroster.com/results/wjvz7sruf3ngamgq', \n",
    "                 'dfname': 'hampton18sprint', \n",
    "             },\n",
    "             'Rockwood2017': {\n",
    "                 'url': 'https://results.raceroster.com/results/7uqq4njwwzqnbn6q', \n",
    "                 'dfname': 'rockwood17sprint',\n",
    "             },\n",
    "             'Rockwood2018': {\n",
    "                 'url': 'https://results.raceroster.com/results/syf4m4gy6sknmzc3?sub_event=13620&query_string=&gender_code=&per_page=500&division=&page=1', \n",
    "                 'dfname': 'rockwood18sprint', \n",
    "             } \n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read tables for the above urls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "for race in list(race_info.keys()):\n",
    "    race_info[race]['df'] = get_rr_table(race_info[race]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.sportstats.ca/display-results.xhtml?raceid=43857&status=results'\n",
    "\n",
    "page = requests.get(url)\n",
    "tree = html.fromstring(page.content)\n",
    "\n",
    "for table in tree.xpath('//table[@class=\"results-listing__table table table-hover table-striped\"]'):\n",
    "    # Get both header rows\n",
    "    header1 = [th.text_content().strip().lower() for th in table.xpath('//thead/tr[1]/th')]\n",
    "    header2 = [th.text_content().strip().lower() for th in table.xpath('//thead/tr[2]/th')]\n",
    "    # Get colspan (and rowspan?) attributes/values, then convert instances of None to 1; also, convert to integers\n",
    "    colspan1 = [th.get(\"colspan\") for th in table.xpath('//thead/tr[1]/th')]\n",
    "    colspan1_int = [1 if element == None else int(element) for element in colspan1]\n",
    "    # Make expanded header 1 (repeat elements as necessary)\n",
    "    header1_expanded = [item for item, count in zip(header1, colspan1_int) for i in range(count)]\n",
    "    # Make corrected header 2 (align elements to header 1)\n",
    "    # For each element in colspan1_int, add an empty string if the orignal value was None,\n",
    "    #   and select the appropriate number of elements from header2 if colspan1_int >1.\n",
    "    #   I could have done this as simply appending elements from header2, but I wanted to \n",
    "    #   write it so that it might still make sense with a different race roster header pattern.\n",
    "    header2_expanded = []  # Initialize empty list\n",
    "    strloc = 0  # Initialize counter variable\n",
    "    for i in colspan1_int:\n",
    "        if i == 1:\n",
    "            header2_expanded.append('')\n",
    "        elif i > 1:\n",
    "            header2_expanded.extend(['-' + element for element in header2[strloc:strloc+i]]) # extend concatenates elements from the list, rather than appending a list (as a sub-list)\n",
    "            strloc += i    \n",
    "    # Combine header rows\n",
    "    header = [h1 + h2 for h1, h2 in zip(header1_expanded, header2_expanded)]\n",
    "    # Get body of table; remove white spaces and \\n; only keep the rows that are the right number of elements\n",
    "    data = [[td.text_content() for td in tr.xpath('td')]  \n",
    "            for tr in table.xpath('//tr')]\n",
    "    for lst in np.arange(start = 0, stop = (len(data)), step = 1):\n",
    "        data[lst] = [element.strip() for element in data[lst]]\n",
    "    data = [row for row in data if len(row)==len(header)]\n",
    "    # Convert to pandas dataframe\n",
    "    data = pd.DataFrame(data, columns=header)\n",
    "    return(data)  # Return pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check shapes; number of rows is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hampton2017: (195, 17)\n",
      "Hampton2018: (217, 12)\n",
      "Rockwood2017: (96, 22)\n",
      "Rockwood2018: (76, 12)\n"
     ]
    }
   ],
   "source": [
    "for race in list(race_info.keys()):\n",
    "    print(race, \": \", race_info[race]['df'].shape, sep = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "* Standardize headers between tables\n",
    "    * The two-row headers for 2017 races add quite a bit of cleanup/replacement here.\n",
    "* Calculate decimal times to do calculations downstream\n",
    "    * This includes renaming original sport columns to include `_hhmmss`\n",
    "* Pull `gender` out of `division`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header standardization\n",
    "\n",
    "At least for Rockwood and Hampton 2018, the headers are the same for:\n",
    "* place\n",
    "* finish\n",
    "* name\n",
    "* city\n",
    "* no.\n",
    "* swim\n",
    "* bike\n",
    "* run\n",
    "* t1\n",
    "* t2\n",
    "\n",
    "The ones that vary are:\n",
    "* `division` vs. `div`\n",
    "* `division place` vs. `div place`\n",
    "\n",
    "For 2017, there is a lot more cleanup that needs to be done. There are also variables that are not in the 2018 data that I am just not working with for now (e.g., `-rank` and `-place` for the different sports).\n",
    "\n",
    "Logic:\n",
    "* If header contains both `div` and `place`, make it `division place`\n",
    "* If header is `div`, change to `division`\n",
    "* 2017-relevant changes:\n",
    "    * `bib` -> `no.`\n",
    "    * `athlete` -> `name`\n",
    "    * `age place` -> `division place`\n",
    "    * `age group` -> `division`\n",
    "    * `gun time` -> `finish`\n",
    "    * `swim-swim` -> `swim`\n",
    "    * `bike-bike` or `bike-enter2` -> `bike`\n",
    "    * `run-run` or `run-finish` -> `run`\n",
    "    * `t1-exit1` to `t1`\n",
    "    * `t2-exit2` to `t2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to process (individual) column header names as above; first create dictionary, then define function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same thing but with a dictionary to set up values to substitute.\n",
    "# Define the dictionary first, and then use it in a function.\n",
    "header_replacement = {\n",
    "    'div place': 'division place',\n",
    "    'div': 'division',\n",
    "    'bib': 'no.',\n",
    "    'athlete': 'name',\n",
    "    'age place': 'division place',\n",
    "    'age group': 'division',\n",
    "    'gun time': 'finish',\n",
    "    'swim-swim': 'swim',\n",
    "    'bike-bike': 'bike',\n",
    "    'bike-enter2': 'bike',\n",
    "    'run-run': 'run',\n",
    "    'run-finish': 'run',\n",
    "    't1-exit1': 't1',\n",
    "    't2-exit2': 't2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_header_names(df):\n",
    "    # get() looks up dictionary value; if not present, returns value listed second\n",
    "    df.columns = [header_replacement.get(element, element) for element in list(df.columns)] \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "for race in list(race_info.keys()):\n",
    "    race_info[race]['df'] = process_header_names(race_info[race]['df'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process both tables (again, this should be done more programmatically when more tables are added):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add variables: decimal times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to convert times to decimal minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_split_min(t):\n",
    "    \"\"\"Convert a time in the format hh:mm:ss into total minutes\"\"\"\n",
    "    if t.count(\":\") == 2 and len(t) == 8:\n",
    "        (h, m, s) = t.split(':')\n",
    "    elif t.count(\":\") == 1 and len(t) == 5:\n",
    "        (m, s) = t.split(':')\n",
    "        h = 0\n",
    "    else:\n",
    "        return\n",
    "    result = int(h) * 60 + int(m) + int(s)/60\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary of replacement column names (`_hhmmss` suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_col_time_names = {'finish': 'finish_hhmmss', \n",
    "                    'swim': 'swim_hhmmss', \n",
    "                    'bike': 'bike_hhmmss', \n",
    "                    'run': 'run_hhmmss', \n",
    "                    't1': 't1_hhmmss', \n",
    "                    't2': 't2_hhmmss'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to rename original columns with `_hhmmss` suffix and add new columns with decimal minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_decimal_minute_columns(df):\n",
    "    # Add _hhmmss to original names using function above (replace original names with _hhmmss names)\n",
    "    df.columns = [sport_col_time_names.get(element, element) for element in list(df.columns)] \n",
    "    # Add new columns with decimal times\n",
    "    for bare, hhmmss in sport_col_time_names.items():\n",
    "        if hhmmss in df.columns:\n",
    "            df[bare] = [time_split_min(element) for element in df[hhmmss]]\n",
    "    # Return processed dataframe\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply above functions to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "for race in list(race_info.keys()):\n",
    "    race_info[race]['df'] = add_decimal_minute_columns(race_info[race]['df'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get `gender` from `division`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gender_from_division(df):\n",
    "    df['gender'] = ['female' if element[0].lower() == 'f' else 'male' for element in df[\"division\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "for race in list(race_info.keys()):\n",
    "    race_info[race]['df']['gender'] = ['female' if element[0].lower() == 'f' else 'male' for element in race_info[race]['df'][\"division\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "for race in list(race_info.keys()):\n",
    "    race_info[race]['df'].to_csv(''.join(['../Data_output/results_', race_info[race]['dfname'], '.csv']), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup code (in the embarrassing absence of version control...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Original version; works when first line of header has all the information I need.\n",
    "# def get_rr_table(url):\n",
    "#     page = requests.get(url)\n",
    "#     tree = html.fromstring(page.content)\n",
    "    \n",
    "#     for table in tree.xpath('//table[@class=\"results-listing__table table table-hover table-striped\"]'):\n",
    "#         # Get first row of header\n",
    "#         # Note that race roster has two rows of the header for the individual sports, \n",
    "#         #   but they're redundant, so I ignore the second.\n",
    "#         #   If the format of the table changed, this could possibly break.\n",
    "#         header = [th.text_content().strip().lower() for th in table.xpath('//thead/tr[1]/th')]\n",
    "#         # Get body of table; remove white spaces and \\n; only keep the rows that are the right number of elements\n",
    "#         data = [[td.text_content() for td in tr.xpath('td')]  \n",
    "#                 for tr in table.xpath('//tr')]\n",
    "#         for lst in np.arange(start = 0, stop = (len(data)), step = 1):\n",
    "#             data[lst] = [element.strip() for element in data[lst]]\n",
    "#         data = [row for row in data if len(row)==len(header)]\n",
    "#         # Convert to pandas dataframe\n",
    "#         data = pd.DataFrame(data, columns=header)\n",
    "#         return(data)  # Return pandas dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
